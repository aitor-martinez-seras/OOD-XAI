{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"OOD_Explainable_AI.ipynb","provenance":[{"file_id":"1eEmr7CAGNrJpVqpKdcRZVDnR4CO6Nspu","timestamp":1628148041981}],"collapsed_sections":["3PrhbK81IQlZ"],"mount_file_id":"1yy8KaElWoYHbWB8RGB06w3kmv1Rg2htK","authorship_tag":"ABX9TyNC67kKkVG82XUEw6T62B+q"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"b55a4d5f7457424da8deed83e4ba8722":{"model_module":"@jupyter-widgets/controls","model_name":"ComboboxModel","model_module_version":"1.5.0","state":{"_view_name":"ComboboxView","style":"IPY_MODEL_bce152e54e0645329bae0cf50fd92a11","_dom_classes":[],"description":"In-Distribution Dataset:","_model_name":"ComboboxModel","placeholder":"Choose the In-Distribution dataset","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Cifar10","_view_count":null,"disabled":false,"_view_module_version":"1.5.0","continuous_update":true,"description_tooltip":null,"ensure_option":true,"_model_module":"@jupyter-widgets/controls","options":["MNIST","Fashion_MNIST","Cifar10"],"layout":"IPY_MODEL_7f2469d6fe2149269593ae245b7f7855"}},"bce152e54e0645329bae0cf50fd92a11":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7f2469d6fe2149269593ae245b7f7855":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":"325px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"23c3b5ff090a4f79b11eb7d0712d61f4":{"model_module":"@jupyter-widgets/controls","model_name":"ComboboxModel","model_module_version":"1.5.0","state":{"_view_name":"ComboboxView","style":"IPY_MODEL_f6aca460fb394a1eb9bfd5ec1ce721cf","_dom_classes":[],"description":"Out-Distribution Dataset:","_model_name":"ComboboxModel","placeholder":"Choose the Out-Distribution dataset","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"MNIST","_view_count":null,"disabled":false,"_view_module_version":"1.5.0","continuous_update":true,"description_tooltip":null,"ensure_option":true,"_model_module":"@jupyter-widgets/controls","options":["MNIST","Fashion_MNIST","SVHN_cropped","Cifar10_grey"],"layout":"IPY_MODEL_b6e3fa1077bc4453b520f3d8ab630d53"}},"f6aca460fb394a1eb9bfd5ec1ce721cf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b6e3fa1077bc4453b520f3d8ab630d53":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":"325px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3bbd4a373ae04828893bbf78af12bc57":{"model_module":"@jupyter-widgets/controls","model_name":"ComboboxModel","model_module_version":"1.5.0","state":{"_view_name":"ComboboxView","style":"IPY_MODEL_a57862989b564c7e990d99b3fd80e9d3","_dom_classes":[],"description":"Models:","_model_name":"ComboboxModel","placeholder":"Choose the Model","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"ResNet32","_view_count":null,"disabled":false,"_view_module_version":"1.5.0","continuous_update":true,"description_tooltip":null,"ensure_option":true,"_model_module":"@jupyter-widgets/controls","options":["ResNet32","Simple_ConvNet"],"layout":"IPY_MODEL_343749f3879a44eda8f73b732537324e"}},"a57862989b564c7e990d99b3fd80e9d3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"343749f3879a44eda8f73b732537324e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":"325px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","source":["***Instructions***:\n","\n","This is the interactive google colab from the paper ____.\n","\n","As explained in the latter, first we train the detector by extracting a random subsample from the training set and creating a class-dependent clusterization of the explanations provided by GradCAM++ heatmaps using the SSIM as similarity measure. Then, we test the detector against and Out-of-Distribution (OoD) dataset and finally we compute the metrics.\n","\n","Follow the titles and instructions to navigate trought all these steps, and be aware that some of them will be widgets created using ``ipywidgets`` that will require you to select the options for the approach you want to test. If the widget does not include a button, just by selecting the option from the dropdown list will be enought to set that value for the programm. If you choose a wrong option or you just want to execute other experiment, just re-run the cell and select the new value. If the widgets contains a button, jsut select the options from the dropdowns and then click the button.\n","\n","For each step which execution is not near-instanteous, a .pkl or a .npy object is created in the `` /content/objects `` directory to allow the user re-execute the experiment without the computational burden of the former. \n","\n","The figures and the results are stored in the `` /content/figures `` and `` /content/results `` directories respectively.\n","\n","As Google Colab enviroment gets automatically updated periodically, some libraries may be different from those originally used in the paper and results may differ. In that case, upload requirements.txt to the enviroment and use `` !pip install -r requirements.txt``, making sure that all packages are installed properly.\n","\n","---"],"metadata":{"id":"HY9qP9IMdNov"}},{"cell_type":"code","metadata":{"id":"Poylp4Em8j0A","cellView":"form"},"source":["#@title Imports\n","# Update to plot with LaTex fonts\n","!apt-get update\n","from matplotlib import rc\n","import matplotlib\n","rc('text', usetex=True)\n","matplotlib.rcParams['text.latex.preamble'] = [r'\\usepackage{amsmath}']\n","!apt install texlive-fonts-recommended texlive-fonts-extra cm-super dvipng\n","# Main libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.utils import to_categorical\n","# Utils\n","from tqdm import tqdm\n","from sklearn.utils import shuffle\n","# Clustering\n","from sklearn.metrics import silhouette_score\n","from sklearn.cluster import AgglomerativeClustering\n","# Image processing and transformations\n","from skimage.transform import resize\n","from skimage.transform import rotate\n","from skimage import transform as trfm\n","from skimage.metrics import structural_similarity as ssim\n","from skimage import color\n","# To handle files\n","import os\n","import pickle\n","from zipfile import ZipFile\n","# Scipy funcitons\n","from scipy import stats\n","from scipy.optimize import minimize_scalar\n","from scipy.io import loadmat\n","from scipy.cluster.hierarchy import dendrogram\n","# To display widgets in Jupyter Notebook\n","import ipywidgets as ipw\n","from IPython.core.display import HTML, display\n","from ipywidgets import widgets\n","# Set LaTex font\n","plt.rcParams.update({\n","    \"text.usetex\": True,\n","    \"font.family\": \"sans-serif\",\n","    \"font.sans-serif\": [\"Helvetica\"]})"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3PrhbK81IQlZ"},"source":["# ***Functions, click play to load all***\n"]},{"cell_type":"code","source":["''' Constants definition  '''\n","# To define the data range for the SSIM comparison. \n","# The data range is 1 as the min value of the pixel is 0 and the max is 1\n","DATA_RANGE = 1\n","OBJS_DIR_NAME = 'objects'\n","!mkdir -p objects"],"metadata":{"id":"ovzVZIP1QI6D"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0aN27frAi6hS"},"source":["## GradCAM"]},{"cell_type":"code","metadata":{"id":"flN8hdFHNrAU"},"source":["def grad_cam_plus(img, model,  layer_name, label_name=None, category_id=None):\n","    \"\"\"Get a heatmap by Grad-CAM.\n","    Args:\n","        model: A model object, build from tf.keras 2.X.\n","        img: An image ndarray.\n","        layer_name: A string, layer name in model.\n","        label_name: A list,\n","            show the label name by assign this argument,\n","            it should be a list of all label names.\n","        category_id: An integer, index of the class.\n","            Default is the category with the highest score in the prediction.\n","    Return:\n","        A heatmap ndarray(without color).\n","    \"\"\"\n","    img_tensor = np.expand_dims(img, axis=0)\n","    conv_layer = model.get_layer(layer_name)\n","    heatmap_model = tf.keras.Model([model.inputs], [conv_layer.output, model.output])\n","    with tf.GradientTape() as gtape1:\n","        with tf.GradientTape() as gtape2:\n","            with tf.GradientTape() as gtape3:\n","                conv_output, predictions = heatmap_model(img_tensor) # De aqui se obtiene (8,8,640)\n","                if category_id is None:\n","                    category_id = np.argmax(predictions[0])\n","                if label_name:\n","                    print(label_name[category_id])\n","                output = predictions[:, category_id]\n","                conv_first_grad = gtape3.gradient(output, conv_output)\n","            conv_second_grad = gtape2.gradient(conv_first_grad, conv_output)\n","        conv_third_grad = gtape1.gradient(conv_second_grad, conv_output)\n","    global_sum = np.sum(conv_output, axis=(0, 1, 2))\n","    # Pixel importance weight \n","    alpha_num = conv_second_grad[0]\n","    alpha_denom = conv_second_grad[0]*2.0 + conv_third_grad[0]*global_sum\n","    alpha_denom = np.where(alpha_denom != 0.0, alpha_denom, 1e-10) # To avoid dividing by zero\n","    alphas = alpha_num/alpha_denom \n","    alpha_normalization_constant = np.sum(alphas, axis=(0,1))\n","    alphas = tf.math.divide_no_nan(alphas,alpha_normalization_constant) \n","    weights = np.maximum(conv_first_grad[0], 0.0) # ReLU to gradients\n","    # Neuron Importance Weights\n","    deep_linearization_weights = np.sum(weights*alphas, axis=(0,1))\n","    grad_CAM_map = np.sum(deep_linearization_weights*conv_output[0], axis=2)\n","    # Only grab positive values\n","    heatmap = np.maximum(grad_CAM_map, 0)\n","    max_heat = np.max(heatmap)\n","    heatmap = tf.math.divide_no_nan(heatmap, max_heat) \n","    return heatmap\n","\n","\n","def grad_cam(img,model, \n","             layer_name=\"block5_conv3\", label_name=None,\n","             category_id=None):\n","    \"\"\"Get a heatmap by Grad-CAM.\n","    Args:\n","        model: A model object, build from tf.keras 2.X.\n","        img: An image ndarray.\n","        layer_name: A string, layer name in model.\n","        label_name: A list,\n","            show the label name by assign this argument,\n","            it should be a list of all label names.\n","        category_id: An integer, index of the class.\n","            Default is the category with the highest score in the prediction.\n","    Return:\n","        A heatmap ndarray(without color).\n","    \"\"\"\n","    img_tensor = np.expand_dims(img, axis=0)\n","\n","    conv_layer = model.get_layer(layer_name)\n","    heatmap_model = keras.Model([model.inputs], [conv_layer.output, model.output])\n","\n","    with tf.GradientTape() as gtape:\n","        conv_output, predictions = heatmap_model(img_tensor)\n","        if category_id == None:\n","            category_id = np.argmax(predictions[0])\n","        if label_name:\n","            print(label_name[category_id])\n","        output = predictions[:, category_id]\n","        grads = gtape.gradient(output, conv_output)\n","        \n","        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n","    heatmap = tf.reduce_mean(tf.multiply(pooled_grads, conv_output), axis=-1)\n","    heatmap = np.maximum(heatmap, 0)\n","    max_heat = np.max(heatmap)\n","    if max_heat == 0:\n","        max_heat = 1e-10\n","    heatmap /= max_heat\n","    return np.squeeze(heatmap)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"09fTwkZWi-Tm"},"source":["## Visualizations"]},{"cell_type":"code","metadata":{"id":"UiRmYMNQjJuj"},"source":["def plot_historia(history):\n","  '''\n","  Plot of the training\n","  '''\n","  acc      = history.history[     'accuracy' ]\n","  val_acc  = history.history[ 'val_accuracy' ]\n","  loss     = history.history[         'loss' ]\n","  val_loss = history.history[     'val_loss' ]\n","  epochs    = range(1,len(acc)+1,1) # obtener número de epochs del eje X\n","\n","  plt.plot  ( epochs,     acc, 'r--', label='Training acc'  )\n","  plt.plot  ( epochs, val_acc,  'b', label='Validation acc')\n","  plt.title ('Training and Validation Accuracy')\n","  plt.ylabel('acc')\n","  plt.xlabel('epochs')\n","  plt.legend()\n","  plt.figure()\n","\n","  plt.plot  ( epochs,     loss, 'r--', label='Training loss'  )\n","  plt.plot  ( epochs, val_loss ,  'b', label='Validation loss' )\n","  plt.title ('Training and Validation Loss'   )\n","  plt.ylabel('loss')\n","  plt.xlabel('epochs')\n","\n","  plt.legend()\n","  plt.figure()\n","\n","\n","def cdf_difference(x,kde_ascending,kde_descending):\n","  '''\n","  Function that calculates the difference between two kdes\n","  '''\n","  cdf_ascending = []\n","  x_0 = np.linspace(-1,1,100)\n","  for i in x_0:\n","    cdf_ascending.append(kde_ascending.integrate_box_1d(-1,i))\n","\n","  y_0 = x_0[::-1]\n","  cdf_descending = []\n","  for i in y_0:\n","    cdf_descending.append(kde_descending.integrate_box_1d(i,1))\n","  difference = cdf_ascending[int(x)] - cdf_descending[int(99-x)]\n","  return abs(difference)\n","\n","\n","def plot_dendrogram(model, **kwargs):\n","    # Create linkage matrix and then plot the dendrogram\n","\n","    # create the counts of samples under each node\n","    counts = np.zeros(model.children_.shape[0])\n","    n_samples = len(model.labels_)\n","    for i, merge in enumerate(model.children_):\n","        current_count = 0\n","        for child_idx in merge:\n","            if child_idx < n_samples:\n","                current_count += 1  # leaf node\n","            else:\n","                current_count += counts[child_idx - n_samples]\n","        counts[i] = current_count\n","\n","    linkage_matrix = np.column_stack([model.children_, model.distances_,\n","                                      counts]).astype(float)\n","\n","    # Plot the corresponding dendrogram\n","    dendrogram(linkage_matrix, **kwargs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Utils"],"metadata":{"id":"JHxY0zRaILxy"}},{"cell_type":"code","source":["def search_index_of_class(class_index, n_times, labels, ini=0):\n","  '''\n","  Returns a list of lenght n_times with the indexes of the labels for a class.\n","  '''\n","  indexes = []\n","  n=0\n","  i=0\n","  while n < n_times:\n","    if class_index == np.argmax(labels[ini+i]):\n","      indexes.append(ini+i)\n","      n = n+1\n","    i = i+1\n","  return indexes"],"metadata":{"id":"MTk8F4ZjIOCx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ElzhnXOxjk7t"},"source":["\n","## Heatmap creation and manipulation\n"]},{"cell_type":"code","metadata":{"id":"F1xuhXkujJ0V"},"source":["def creation_of_heatmaps_per_class(number_of_htmaps,instances,labels):\n","  '''\n","  Creates an array with the number of heatmaps selected per class\n","  '''\n","  heatmaps = np.empty((NUM_CLASSES,number_of_htmaps,model.get_layer(LAST_CONV_LAYER).output.shape[1],model.get_layer(LAST_CONV_LAYER).output.shape[2]))\n","  for class_index in tqdm(range(NUM_CLASSES)):\n","    # List of index of the labels for the class\n","    indexes_for_one_class = search_index_of_class(class_index,number_of_htmaps,labels)\n","    for loop_index,label_index in enumerate(indexes_for_one_class):\n","      # Fill the array with the heatmaps\n","      heatmaps[class_index,loop_index] = grad_cam_plus(instances[label_index],model,LAST_CONV_LAYER,category_id=np.argmax(labels[label_index]))\n","  return heatmaps\n","\n","\n","def compute_average_heatmaps_per_cluster(cluster_indexes, heatmaps_array, ssim_distance_matrix_one_class, agg_funct, thr=None):\n","  '''\n","  Computes the average per cluster of the provided heatmaps\n","  ::cluster_indexes: array with the cluster indexes\n","  ::heatmaps_array: array with the heatmaps. Shape = [number_of_htmaps, height, width]\n","  ::agg_funct: string that defines how to do the average\n","  ::thr: if we want to compute the average only on a percentage of the closest ones\n","          the threshold parameter should be included with the percentage in the range\n","          of 0 to 1.\n","  :Returns: array with the average heatmap per cluster\n","  ''' \n","  # Extract unique numbers and how much of them are\n","  unique, counts = np.unique(cluster_indexes, return_counts=True)\n","  # Eliminate index -1 because it refers to outliers\n","  if -1 in unique:\n","    unique = np.delete(unique,0)\n","    counts = np.delete(counts,0)\n","  # Initialize the array where the average heatmaps are going to be stored\n","  agg_htmaps_per_cluster = np.empty((len(unique),heatmaps_array.shape[1],heatmaps_array.shape[2]))\n","  for index_unique,cluster in enumerate(unique):\n","    # Retrieve the indexes of the cluster\n","    indexes_one_cluster = np.asarray(np.asarray(cluster_indexes == cluster).nonzero()[0])\n","    # Either retrieve only the closest heatmaps of that cluster OR retrieve all\n","    if thr is not None and len(indexes_one_cluster) > 39: # Retrieval of only the closest ones\n","      # Initialize the array that will contain the mean D_ssim of each heatmap against the heatmaps of the cluster including itself\n","      mean_dist_ssim_of_htmaps_of_cluster = np.zeros((len(indexes_one_cluster)))\n","      for loop_index_1, index_htmap_1 in enumerate(indexes_one_cluster):\n","        # Initialize the array that will be used to collect the ssim values against the others to then compute the mean\n","        dist_ssim_of_one_htmap_against_all = np.zeros((len(indexes_one_cluster)))\n","        for loop_index_2, index_htmap_2 in enumerate(indexes_one_cluster):\n","          dist_ssim_of_one_htmap_against_all[loop_index_2] = ssim_distance_matrix_one_class[index_htmap_1, index_htmap_2]\n","        mean_dist_ssim_of_htmaps_of_cluster[loop_index_1] = np.mean(dist_ssim_of_one_htmap_against_all)\n","      # Sort mean ascending\n","      indexes_images_sorted_per_dist_ssim = np.argsort(mean_dist_ssim_of_htmaps_of_cluster)\n","      # Extract the introduced percent more closer of the cluster using thr parameter\n","      indexes_for_average_computation_percent = indexes_images_sorted_per_dist_ssim[:int(thr*len(mean_dist_ssim_of_htmaps_of_cluster))]\n","      htmaps_of_the_cluster = heatmaps_array[indexes_one_cluster][indexes_for_average_computation_percent]\n","\n","    else: # Retrieval of all the heatmaps of the cluster\n","      indexes_one_cluster = np.sort(indexes_one_cluster)\n","      htmaps_of_the_cluster = heatmaps_array[indexes_one_cluster]\n","\n","    # Compute the average depending on the mode selected\n","    if agg_funct == 'Mean':\n","      #print(htmaps_of_the_cluster.shape)\n","      htmap_prom_un_cluster = np.mean(htmaps_of_the_cluster, axis=0)\n","\n","    elif agg_funct == 'Median':\n","      htmap_prom_un_cluster = np.median(htmaps_of_the_cluster, axis=0)\n","    else:\n","      raise NameError('Non-existant mode introduced')\n","    # For every cluster we add its average heatmap\n","    agg_htmaps_per_cluster[index_unique] = htmap_prom_un_cluster\n","\n","  return agg_htmaps_per_cluster\n","\n","  \n","def generate_heatmaps(images,preds):\n","  '''\n","  Generates the heatmaps of the images provided using the prediction (the label)\n","  '''\n","  htmaps = np.zeros((images.shape[0],model.get_layer(LAST_CONV_LAYER).output.shape[1],model.get_layer(LAST_CONV_LAYER).output.shape[2]))\n","  for i,image in tqdm(enumerate(images)):\n","    htmaps[i] = grad_cam_plus(image,model,LAST_CONV_LAYER,category_id=preds[i])\n","  return htmaps"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-whNDZ6cXy9J"},"source":["## SSIM related functions"]},{"cell_type":"code","metadata":{"id":"QNwYPDSvlJlJ"},"source":["def cw_ssim(img1, img2):\n","  '''\n","  Function that receives two numpy array images and computes CW-SSIM\n","  '''\n","  img1 = PIL.Image.fromarray(np.uint8(img1*255))\n","  img2 = PIL.Image.fromarray(np.uint8(img2*255))\n","  # FOR EXPERIMENTS ONLY!\n","  # Very slow algorithm - up to 50x times slower than SIFT or SSIM.\n","  # Optimization using CUDA or Cython code should be explored in the future.\n","  return pyssim.SSIM(img1).cw_ssim_value(img2)\n","\n","\n","def ssim_distance_matrix_creation(heatmaps_array):\n","  '''\n","  Creates an upper triangular array with the pairwise distances between each heatmap in the array provided.\n","  '''\n","  ssim_mat = np.zeros((len(heatmaps_array),len(heatmaps_array)))\n","  for i,htmap in enumerate(heatmaps_array):\n","    # We visit every column which index is greater than the index of the current row.\n","    # The diagonal is not visited as the distance between two identical images is 0 \n","    # and the array is defined all zeros.\n","    for j in range(i+1,len(heatmaps_array)):\n","      ssim_mat[i,j] = ssim_distance(htmap,heatmaps_array[j])\n","      ssim_mat[j,i] = ssim_mat[i,j]\n","  return ssim_mat\n","\n","\n","def ssim_distance(img1,img2):\n","  '''\n","  Computed the Dssim between two images, defined as: \n","  Dssim = (1 - SSIM)/2 \n","  This way, obtained value is between 0 and 1, 0 being distance between identical images\n","  '''  \n","  return (1-ssim(img1,img2, data_range=DATA_RANGE))/2\n","\n","\n","def compute_ssim_against_cluster_averages(input_heatmaps,preds,agg_htmaps_per_class_and_cluster,mode='Similarity'):\n","  '''\n","  Computes the ssim of the input heatmaps against the cluster averages of the predicted class\n","  '''\n","  # Initialize the array containing the SSIM values\n","  ssim_per_input_heatmap = np.zeros((len(input_heatmaps)))\n","  for index,predicted_class in tqdm(enumerate(preds)):\n","    # Initialize the aray containing the SSIM values against cluster averages for one input heatmap\n","    ssim_against_cluster_aggs = np.zeros((agg_htmaps_per_class_and_cluster[predicted_class].shape[0]))\n","    if mode == 'Similarity':\n","      for index_agg_htmap, agg_htmap  in enumerate(agg_htmaps_per_class_and_cluster[predicted_class]):\n","        ssim_against_cluster_aggs[index_agg_htmap] = ssim(agg_htmap,input_heatmaps[index], data_range=DATA_RANGE)\n","    elif mode == 'Distance':\n","      for index_agg_htmap, agg_htmap  in enumerate(agg_htmaps_per_class_and_cluster[predicted_class]):\n","        ssim_against_cluster_aggs[index_agg_htmap] = ssim_distance(agg_htmap,input_heatmaps[index])\n","    else:\n","      raise NameError('Selected mode does not exist')\n","    # Select the more similar average heatmap (the max SSIM value)  \n","    ssim_per_input_heatmap[index] = np.max(ssim_against_cluster_aggs) \n","  return ssim_per_input_heatmap\n","\n","\n","def compute_ssim_against_all_heatmps_of_closest_cluster(input_heatmaps, preds, agg_htmaps_per_class_and_cluster, heatmaps_in_the_clusters_per_class, cluster_indexes_of_heatmaps):\n","  '''\n","  Computes the ssim of the input heatmaps against all the heatmaps of the closest cluster of the predicted class.\n","  First computes the SSIM against cluster averages, and it selects the max similarity (max ssim).\n","  Then computes the SSIM against all the heatmaps belonging to that cluster\n","  '''\n","  # Initialize the array that will contain the SSIM values\n","  ssim_per_input_heatmap = np.zeros((len(input_heatmaps)))\n","  for index,predicted_class in tqdm(enumerate(preds)):\n","    # Initialize the array that will contain the SSIM values to the cluster averages.\n","    ssim_against_cluster_aggs = np.zeros((len(agg_htmaps_per_class_and_cluster[predicted_class])))\n","    for index_agg_htmap, agg_htmap in enumerate(agg_htmaps_per_class_and_cluster[predicted_class]):\n","      # Calculamos cual las distancias a cada cluster y nos quedamos con el heatmap mas cercano del cluster mas cercano\n","      ssim_against_cluster_aggs[index_agg_htmap] = ssim(input_heatmaps[index],agg_htmap, data_range=DATA_RANGE)\n","      closest_cluster_index = np.argmax(ssim_against_cluster_aggs) # Max similarity == Closest cluster\n","    # Indexes of the heatmaps that belong to the nearest cluster.\n","    indexes_of_closest_cluster_heatmaps = np.asarray(np.asarray(cluster_indexes_of_heatmaps[predicted_class] == closest_cluster_index).nonzero()[0])\n","    # Compute every SSIM value to the heatmaps in the closest cluster\n","    # Initialze the array that will contain the SSIM values against all heatmaps in closest cluster\n","    ssim_against_closest_cluster_heatmaps = np.zeros((len(indexes_of_closest_cluster_heatmaps)))\n","    for i, htmap_indexes in enumerate(indexes_of_closest_cluster_heatmaps):\n","      ssim_against_closest_cluster_heatmaps[i] = ssim(input_heatmaps[index],heatmaps_in_the_clusters_per_class[predicted_class,htmap_indexes], data_range=DATA_RANGE)\n","    # Select the more similar average heatmap (the max SSIM value) \n","    ssim_per_input_heatmap[index] = np.max(ssim_against_closest_cluster_heatmaps) \n","  return ssim_per_input_heatmap"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Metrics"],"metadata":{"id":"PKbBj6N1C2xt"}},{"cell_type":"code","source":["# Similarity\n","def similarity_thresholds_for_each_TPR(similarity_test):\n","  # Creation of the array with the thresholds for each TPR (class, dist_per_TPR)\n","  sorted_similarity_test = [np.sort(x)[::-1] for x in similarity_test]\n","  tpr_range = np.arange(0,1,0.005)\n","  tpr_range[-1] = 0.99999999 # For selecting the last item correctly\n","  similarity_thresholds_test = np.zeros((NUM_CLASSES, len(tpr_range)))\n","  for class_index in range(NUM_CLASSES):\n","    for index, tpr in enumerate(tpr_range):\n","      similarity_thresholds_test[class_index, index] = sorted_similarity_test[class_index][int(len(sorted_similarity_test[class_index])*tpr)]\n","  return similarity_thresholds_test\n","\n","\n","def compare_similarity_to_similarity_thrs(distances_list_per_class, thr_distances_array):\n","  '''\n","  Function that creates an array of shape (tpr, InD_or_OD), where tpr has the lenght of the number of steps of the TPR list\n","  and second dimensions has the total lenght of the distances_list_per_class, and cotains True if its InD and False if is OD\n","  :distances_list_per_class: list with each element being an array with the distances to agg clusters of one class [array(.), array(.)]\n","  :thr_distances_array: array of shape (class, dist_for_each_tpr), where first dimension is the class and the second is the distance for the TPR\n","   corresponding to that position. For example, the TPR = 0.85 corresponds to the 85th position.\n","  '''\n","  in_or_out_distribution_per_tpr = np.zeros((len(np.transpose(thr_distances_array)),len(np.concatenate(distances_list_per_class))),dtype=bool)\n","  for tpr_index ,thr_distances_per_class in enumerate(np.transpose(thr_distances_array)):\n","      in_or_out_distribution_per_tpr[tpr_index] = np.concatenate([dist_one_class > thr_distances_per_class[cls_index] for cls_index, dist_one_class in enumerate(distances_list_per_class)])\n","    \n","  return in_or_out_distribution_per_tpr\n","\n","\n","def compute_precision_tpr_fpr_for_test_and_OoD_similarity(dist_test, dist_OoD,dist_thresholds_test):\n","  # Creation of the array with True if predicted InD (True) or OD (False)\n","  in_or_out_distribution_per_tpr_test = compare_similarity_to_similarity_thrs(dist_test, dist_thresholds_test)\n","  in_or_out_distribution_per_tpr_test[0] = np.zeros((in_or_out_distribution_per_tpr_test.shape[1]),dtype=bool) # To fix that first element is True when TPR is 0\n","  in_or_out_distribution_per_tpr_test[-1] = np.ones((in_or_out_distribution_per_tpr_test.shape[1]),dtype=bool) # To fix that last element is True when TPR is 1\n","  in_or_out_distribution_per_tpr_OoD = compare_similarity_to_similarity_thrs(dist_OoD, dist_thresholds_test)\n","\n","  # Creation of arrays with TP, FN and FP, TN\n","  tp_fn_test = tp_fn_fp_tn_computation(in_or_out_distribution_per_tpr_test)\n","  fp_tn_OoD = tp_fn_fp_tn_computation(in_or_out_distribution_per_tpr_OoD)\n","\n","  # Computing TPR, FPR and Precision\n","  tpr_values = tp_fn_test[:,0] / (tp_fn_test[:,0] + tp_fn_test[:,1])\n","  fpr_values = fp_tn_OoD[:,0] / (fp_tn_OoD[:,0] + fp_tn_OoD[:,1])\n","  precision  = tp_fn_test[:,0] / (tp_fn_test[:,0] + fp_tn_OoD[:,0])\n","\n","  # Eliminating NaN value at TPR = 1\n","  precision[0] = 1\n","  return precision, tpr_values, fpr_values\n","\n","\n","# For both\n","def tp_fn_fp_tn_computation(in_or_out_distribution_per_tpr):\n","  '''\n","  Function that creates an array with the number of values of tp and fp or fn and tn, depending on if the \n","  passed array is InD or OD.\n","  :in_or_out_distribution_per_tpr: array with True if predicted InD and False if predicted OD, for each TPR\n","  ::return: array with shape (tpr, 2) with the 2 dimensions being tp,fn if passed array is InD, and fp and tn if the passed array is OD\n","  '''\n","  tp_fn_fp_tn = np.zeros((len(in_or_out_distribution_per_tpr),2),dtype='uint16')\n","  length_array = in_or_out_distribution_per_tpr.shape[1]\n","  for index, element in enumerate(in_or_out_distribution_per_tpr):\n","    n_True = int(len(element.nonzero()[0]))\n","    tp_fn_fp_tn[index,0] = n_True\n","    tp_fn_fp_tn[index,1] = length_array - n_True\n","  return tp_fn_fp_tn"],"metadata":{"id":"biMRicVeC22t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y5MmWt2C3RCj"},"source":["## Dataset loading and transforming functions"]},{"cell_type":"code","metadata":{"id":"EVwoC6Wh3RHI"},"source":["def download_SVHN():\n","  '''\n","  Function that downloads the SVHN Cropped dataset\n","  '''\n","  !cd /content/\n","  !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Qezu-SHyjBF_fGwdFYUSioVbAu3GMfBj' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1Qezu-SHyjBF_fGwdFYUSioVbAu3GMfBj\" -O SVHN_Cropped.zip && rm -rf /tmp/cookies.txt\n","  return '/content/SVHN_Cropped.zip'\n","\n","\n","def download_weights_and_model():\n","  '''\n","  Function that downloads the weights and the ResNet32v1 model from Google Drive\n","  '''\n","  %cd /content/\n","  !wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1kubVcEv8ORheY0_3NuGb7VwE8OMbX5G9' -O OoD_xAI.zip\n","  return '/content/OoD_xAI.zip'\n","\n","\n","def unzip_file(zip_file_path):\n","  '''\n","  Function that extracts the zip file and deletes it, returnin the new file path\n","  '''\n","  # Create a ZipFile Object and load sample.zip in it\n","  with ZipFile(zip_file_path, 'r') as zipObj:\n","    # Extract all the contents of zip file in current directory\n","    zipObj.extractall()\n","  !rm -r $zip_file_path\n","  return zip_file_path[:-4]\n","\n","\n","def load_svhn(image_dir, image_file):\n","  print ('Loading SVHN dataset.')\n","  image_dir = os.path.join(image_dir, image_file)\n","  svhn = loadmat(image_dir)\n","  images = np.transpose(svhn['X'], [3, 0, 1, 2]).astype('float32')/255\n","  labels = svhn['y']\n","  labels[np.where(labels==10)] = 0\n","  labels = to_categorical(labels)\n","  return images, labels\n","\n","\n","def load_test_sample_of_dataset(dataset_name):\n","  # Load the selected dataset\n","  if dataset_name == 'SVHN_cropped':\n","    # Download SVHN\n","    SVHN_FOLDER_PATH = unzip_file(download_SVHN())\n","    images, labels = load_svhn(SVHN_FOLDER_PATH,\"test_32x32.mat\")\n","    np.random.shuffle(images)\n","    images = images[:10000]\n","  elif dataset_name == 'MNIST':\n","    (_, _), (images, labels) = tf.keras.datasets.mnist.load_data()\n","    images = images/255\n","    images = images.reshape(10000,28,28,1)\n","    images = images.astype('float32')\n","    labels = to_categorical(labels)\n","  elif dataset_name == 'Fashion_MNIST':\n","    (_, _), (images, labels) = tf.keras.datasets.fashion_mnist.load_data()\n","    images = images/255\n","    images = images.reshape(10000,28,28,1)\n","    images = images.astype('float32')\n","  elif dataset_name == 'MNIST_color':\n","    (_, _), (images, labels) = tf.keras.datasets.mnist.load_data()\n","    images = images/255\n","    images = images.reshape(10000,28,28,1)\n","    images = images.astype('float32')\n","    images = np.tile(images,3)\n","    images = resize(images,(10000, 32, 32, 3)) \n","  elif dataset_name == 'Fashion_MNIST_color':\n","    (_, _), (images, labels) = tf.keras.datasets.fashion_mnist.load_data()\n","    images = images/255\n","    images = images.reshape(10000,28,28,1)\n","    images = images.astype('float32')\n","    images = np.tile(images,3)\n","    images = resize(images,(10000, 32, 32, 3))\n","  elif dataset_name == 'Cifar10_grey':\n","    cifar = tf.keras.datasets.cifar10\n","    (_, _), (images, labels) = cifar.load_data()\n","    # Damos el formato correspondiente a las imagenes\n","    images = images.reshape(10000, 32, 32, 3)\n","    images = images.astype('float32') / 255\n","    images = np.expand_dims(color.rgb2gray(images),axis=3)\n","    images = resize(images,(10000, 28, 28, 1))\n","  elif dataset_name == 'Cifar10':\n","    cifar = tf.keras.datasets.cifar10\n","    (_, _), (images, labels) = cifar.load_data()\n","    # Damos el formato correspondiente a las imagenes\n","    images = images.reshape(10000, 32, 32, 3)\n","    images = images.astype('float32') / 255\n","  else:\n","    raise NameError()\n","  return images, labels\n","\n","\n","# Rotate images (17s 60.000 images)\n","def rotate_images(images, angle):\n","  for i,img in enumerate(images):\n","    images[i] = rotate(img,angle)\n","  return images\n","\n","\n","# Translation\n","def translate_images(images, h_trans, v_trans):\n","  translation = (h_trans,v_trans)\n","  tform = trfm.SimilarityTransform(translation=translation)\n","  for i,img in enumerate(images):\n","    images[i] = trfm.warp(img, tform)\n","  return images"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VfNdK2sIh7dA"},"source":["---\n","# ***Dataset and model selection***\n","---"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":50,"referenced_widgets":["b55a4d5f7457424da8deed83e4ba8722","bce152e54e0645329bae0cf50fd92a11","7f2469d6fe2149269593ae245b7f7855"]},"id":"RFeeCXpedOfP","cellView":"form","executionInfo":{"status":"ok","timestamp":1644577617138,"user_tz":-60,"elapsed":248,"user":{"displayName":"Aitor Martinez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09566376405051483384"}},"outputId":"453cfbb2-b695-4060-f0da-b6c870721635"},"source":["#@title Click Play to select the In-Distribution Dataset\n","greyChannelDatasets = ['MNIST','Fashion_MNIST']\n","colorDatasets       = ['Cifar10']\n","datasetOptions = greyChannelDatasets + colorDatasets\n","selectedDataset = widgets.Combobox(\n","    placeholder='Choose the In-Distribution dataset',\n","    options=datasetOptions,\n","    description='In-Distribution Dataset:',\n","    ensure_option=True,\n","    disabled=False,\n","    layout = ipw.Layout(width='325px')\n",")\n","selectedDataset"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b55a4d5f7457424da8deed83e4ba8722","version_minor":0,"version_major":2},"text/plain":["Combobox(value='', description='In-Distribution Dataset:', ensure_option=True, layout=Layout(width='325px'), o…"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":50,"referenced_widgets":["23c3b5ff090a4f79b11eb7d0712d61f4","f6aca460fb394a1eb9bfd5ec1ce721cf","b6e3fa1077bc4453b520f3d8ab630d53"]},"id":"EC3hNQkDKDH1","cellView":"form","executionInfo":{"status":"ok","timestamp":1644577487716,"user_tz":-60,"elapsed":238,"user":{"displayName":"Aitor Martinez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09566376405051483384"}},"outputId":"152d587c-b93f-4750-a0be-1e829a7fe3e3"},"source":["#@title Click Play to select the Out-Distribution Dataset\n","odDatasetsOptions_color = ['MNIST_color','Fashion_MNIST_color','SVHN_cropped', 'Cifar10']\n","odDatasetsOptions_grey_mnist  = ['MNIST','Fashion_MNIST','SVHN_cropped','Cifar10_grey']\n","odDatasetsOptions_grey_fashion  = ['MNIST','Fashion_MNIST','SVHN_cropped','Cifar10_grey']\n","if selectedDataset.value in greyChannelDatasets:\n","  if selectedDataset.value == greyChannelDatasets[0]:\n","    OD_dataset  = widgets.Combobox(\n","        placeholder='Choose the Out-Distribution dataset',\n","        options=odDatasetsOptions_grey_mnist,\n","        description='Out-Distribution Dataset:',\n","        ensure_option=True,\n","        disabled=False,\n","        layout = ipw.Layout(width='325px')\n","    )\n","  else:\n","    OD_dataset  = widgets.Combobox(\n","        placeholder='Choose the Out-Distribution dataset',\n","        options=odDatasetsOptions_grey_fashion,\n","        description='Out-Distribution Dataset:',\n","        ensure_option=True,\n","        disabled=False,\n","        layout = ipw.Layout(width='325px')\n","    )\n","else:\n","  OD_dataset  = widgets.Combobox(\n","      placeholder='Choose the Out-Distribution dataset',\n","      options=odDatasetsOptions_color,\n","      description='Out-Distribution Dataset:',\n","      ensure_option=True,\n","      disabled=False,\n","      layout = ipw.Layout(width='325px')\n","  )\n","OD_dataset"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"23c3b5ff090a4f79b11eb7d0712d61f4","version_minor":0,"version_major":2},"text/plain":["Combobox(value='', description='Out-Distribution Dataset:', ensure_option=True, layout=Layout(width='325px'), …"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":50,"referenced_widgets":["3bbd4a373ae04828893bbf78af12bc57","a57862989b564c7e990d99b3fd80e9d3","343749f3879a44eda8f73b732537324e"]},"id":"_OrbcMAFfAGr","cellView":"form","executionInfo":{"status":"ok","timestamp":1644577621343,"user_tz":-60,"elapsed":276,"user":{"displayName":"Aitor Martinez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09566376405051483384"}},"outputId":"f581deb2-e56a-4a44-8823-e4dea8388491"},"source":["#@title Click Play to chose the model\n","greyModelOptions  = ['LeNet']\n","colorModelOptions = ['ResNet32']\n","\n","if selectedDataset.value in greyChannelDatasets:\n","\n","    selectedModel = widgets.Combobox(\n","        placeholder='Choose the Model',\n","        options=greyModelOptions,\n","        description='Models:',\n","        ensure_option=True,\n","        disabled=False,\n","        layout = ipw.Layout(width='325px')\n","        )\n","\n","else:\n","  selectedModel = widgets.Combobox(\n","      placeholder='Choose the Model',\n","      options=colorModelOptions,\n","      description='Models:',\n","      ensure_option=True,\n","      disabled=False,\n","      layout = ipw.Layout(width='325px')\n","      )\n","\n","selectedModel"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3bbd4a373ae04828893bbf78af12bc57","version_minor":0,"version_major":2},"text/plain":["Combobox(value='', description='Models:', ensure_option=True, layout=Layout(width='325px'), options=('ResNet32…"]},"metadata":{}}]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"5EgTz6l4QCN-"}},{"cell_type":"code","metadata":{"id":"oFKBV3yA8o6s","cellView":"form"},"source":["#@title Load the selected dataset and model\n","# Extract the name of the chosen dataset\n","DATASET_NAME = selectedDataset.value\n","OD_DATASET_NAME = OD_dataset.value\n","SEED = 8 # Predefine the seed, just in case the used does not use the widget\n","# Dowload pretrained weights and ResNet32v1 model\n","try:\n","  if os.path.isdir(PRETRAINED_WEIGHTS_AND_MODEL_FOLDER_PATH):\n","    pass\n","  else:\n","    PRETRAINED_WEIGHTS_AND_MODEL_FOLDER_PATH = unzip_file(download_weights_and_model())\n","except NameError:\n","  PRETRAINED_WEIGHTS_AND_MODEL_FOLDER_PATH = unzip_file(download_weights_and_model())\n","if DATASET_NAME == 'Cifar10':\n","  cifar = tf.keras.datasets.cifar10\n","  (train_images, train_labels_clases), (test_images, test_labels_clases) = cifar.load_data()\n","  # Format images\n","  train_images = train_images.reshape(50000, 32, 32, 3)\n","  train_images = train_images.astype('float32') / 255\n","  test_images = test_images.reshape(10000, 32, 32, 3)\n","  test_images = test_images.astype('float32') / 255\n","  # Labels to categorical (10 dimensions with a 1 in the correspondent class)\n","  train_labels = to_categorical(train_labels_clases)\n","  test_labels = to_categorical(test_labels_clases)\n","  # Definition of the constants of the dataset\n","  CLASS_NAMES = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n","  NUM_CLASSES = len(CLASS_NAMES)\n","\n","elif DATASET_NAME == 'SVHN_Cropped':\n","  # Download SVHN\n","  SVHN_FOLDER_PATH = unzip_file(download_SVHN())\n","  # Load SVHN\n","  train_images, train_labels = load_svhn(SVHN_FOLDER_PATH, 'train_32x32.mat')\n","  test_images, test_labels = load_svhn(SVHN_FOLDER_PATH,'test_32x32.mat')\n","  # Definition of the constants of the dataset\n","  CLASS_NAMES = list(np.linspace(0,9,10).astype('int'))\n","  CLASS_NAMES = [str(i) for i in CLASS_NAMES]\n","  NUM_CLASSES = len(CLASS_NAMES)\n","\n","elif DATASET_NAME == 'MNIST':\n","  # Load the dataset\n","  (train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n","  # Reduce the range of the images to [0,1]\n","  train_images = train_images/255\n","  test_images = test_images/255\n","  # Format images\n","  train_images = train_images.reshape(60000,28,28,1)\n","  train_images = train_images.astype('float32')\n","  test_images = test_images.reshape(10000,28,28,1)\n","  test_images = test_images.astype('float32')\n","  # Labels to categorical (10 dimensions with a 1 in the correspondent class)\n","  train_labels = to_categorical(train_labels)\n","  test_labels = to_categorical(test_labels)\n","  # Definition of the constants of the dataset\n","  CLASS_NAMES = list(np.linspace(0,9,10).astype('int'))\n","  CLASS_NAMES = [str(i) for i in CLASS_NAMES]\n","  NUM_CLASSES = len(CLASS_NAMES)\n","  \n","\n","elif DATASET_NAME == 'Fashion_MNIST':\n","  # Load F_MNIST dataset\n","  fashion_mnist = tf.keras.datasets.fashion_mnist\n","  (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n","  # Reduce the range of the images to [0,1]\n","  train_images = train_images/255\n","  test_images = test_images/255\n","  # Format images\n","  train_images = train_images.reshape(60000,28,28,1)\n","  train_images = train_images.astype('float32')\n","  test_images = test_images.reshape(10000,28,28,1)\n","  test_images = test_images.astype('float32')\n","  # Labels to categorical (10 dimensions with a 1 in the correspondent class)\n","  from tensorflow.keras.utils import to_categorical\n","  train_labels = to_categorical(train_labels)\n","  test_labels = to_categorical(test_labels)\n","  # Definition of the constants of the dataset\n","  CLASS_NAMES = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']\n","  NUM_CLASSES = len(CLASS_NAMES)\n","\n","else:\n","  raise NameError('Dataset name not found in the dataset options')\n","\n","# Extract the name of the chosen model\n","MODEL_NAME = selectedModel.value \n","# The input shape of the dataset\n","INPUT_SHAPE = (train_images[0].shape)\n","if DATASET_NAME in greyChannelDatasets:\n","\n","  if MODEL_NAME == 'Custom_ConvNet':\n","    model = keras.Sequential(\n","          [\n","          keras.layers.InputLayer(input_shape=INPUT_SHAPE),\n","          keras.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\",name='conv2d'),\n","          keras.layers.MaxPooling2D(pool_size=(2, 2), name= 'max_pooling2d'),\n","          keras.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\",name='conv2d_1'),\n","          keras.layers.MaxPooling2D(pool_size=(2, 2), name= 'max_pooling2d_1'),\n","          keras.layers.Dropout(0.25,name='dropout'),\n","          keras.layers.Flatten(name='flatten'),\n","          keras.layers.Dense(64,activation='relu',name='dense'),\n","          keras.layers.Dropout(0.25,name='dropout_1'),\n","          keras.layers.Dense(10, activation=\"softmax\", name='softmax'),\n","          ]\n","          )\n","\n","    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","\n","  elif MODEL_NAME == 'LeNet':\n","    model = keras.Sequential(\n","        [\n","          keras.layers.InputLayer(input_shape=INPUT_SHAPE),\n","          keras.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\",name='conv2d'),\n","          keras.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\",name='conv2d_1'),\n","          keras.layers.MaxPooling2D(pool_size=(2, 2), name= 'max_pooling2d_1'),\n","          keras.layers.Dropout(0.25,name='dropout'),\n","          keras.layers.Flatten(name='flatten'),\n","          keras.layers.Dense(128,activation='relu',name='dense'),\n","          keras.layers.Dropout(0.25,name='dropout_1'),\n","          keras.layers.Dense(10, activation=\"softmax\", name='softmax'),\n","\n","        ]\n","    )\n","\n","    # As in the github example\n","    def scheduler(epoch, lr):\n","      if epoch < 10:\n","        return lr\n","      else:\n","        return lr * 0.7\n","\n","    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","\n","else:\n","    \n","  if  MODEL_NAME == 'WideResnet_28_10':\n","\n","    %cd /content/drive/MyDrive/Colab_Notebooks/3_OOD_XAI/Models\n","    model = tf.keras.models.load_model('WRSNT_28_10')\n","\n","    # Creamos la intancia de ImageDataGenerator que procesará las imagenes de entrada\n","    # La ZCA whitening sobreescribe el Featureweise_std_norm por lo que no importa que sea True o False\n","    test_datagen = keras.preprocessing.image.ImageDataGenerator(\n","                        featurewise_center=True,\n","                        featurewise_std_normalization=False, \n","                        zca_whitening=True)\n","    test_datagen.fit(train_images)\n","\n","    # Creation of the arrays with preprocessed train and test split\n","    batch_size_img_preprocesor = 100\n","    seed_img_preprocessor      = 5\n","\n","    # Creation of the object containing the batches of (images, labels)\n","    batches = test_datagen.flow(train_images,train_labels,seed=seed_img_preprocessor,shuffle=True,batch_size=batch_size_img_preprocesor)\n","\n","    # Loop for extracting all the batches of train\n","    for i in range(int(len(train_images)/batch_size_img_preprocesor)): #1st batch is alread fetched before the for loop\n","      imgs, labels = next(batches)\n","      train_images[i:i+batch_size_img_preprocesor] = imgs\n","      train_labels[i:i+batch_size_img_preprocesor] = labels\n","\n","    # Same for test\n","    batches = test_datagen.flow(test_images,test_labels,seed=seed_img_preprocessor,shuffle=True,batch_size=batch_size_img_preprocesor)\n","\n","    for i in range(int(len(test_images)/batch_size_img_preprocesor)):\n","      imgs, labels = next(batches)\n","      test_images[i:i+batch_size_img_preprocesor] = imgs\n","      test_labels[i:i+batch_size_img_preprocesor] = labels\n","\n","    print(train_images.shape, train_labels.shape)\n","    print(test_images.shape, test_labels.shape)\n","\n","\n","  elif MODEL_NAME == 'VGG16':\n","\n","    model = tf.keras.applications.VGG16(\n","      include_top=False,\n","      weights=\"imagenet\",\n","      input_tensor=None,\n","      input_shape=(train_images.shape[1:]),\n","      pooling=None,\n","      classes=1000,\n","      classifier_activation=\"softmax\"\n","    )\n","\n","  elif MODEL_NAME =='ResNet32':\n","    %pip install download\n","    %cd $PRETRAINED_WEIGHTS_AND_MODEL_FOLDER_PATH\n","    # Import the function to create the model and create it\n","    from resnet_32 import create_model\n","    model = create_model((32,32,3),10,'ResNet32v1')\n","    %cd /content/\n","\n","  elif MODEL_NAME == 'Simple_ConvNet':\n","    model = Sequential()\n","    # CONV => RELU => CONV => RELU => POOL => DROPOUT\n","    model.add(Conv2D(32, (3, 3), padding='same',activation='relu',input_shape=INPUT_SHAPE))\n","    model.add(Conv2D(32, (3, 3), activation='relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Dropout(0.25))\n","\n","    # CONV => RELU => CONV => RELU => POOL => DROPOUT\n","    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n","    model.add(Conv2D(64, (3, 3), activation='relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Dropout(0.25))\n","\n","    # FLATTERN => DENSE => RELU => DROPOUT\n","    model.add(Flatten())\n","    model.add(Dense(512, activation ='relu'))\n","    model.add(Dropout(0.5))\n","    # a softmax classifier\n","    model.add(Dense(NUM_CLASSES))\n","    model.add(Activation('softmax'))\n","    # initiate RMSprop optimizer\n","    opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n","    # Let's train the model using RMSprop\n","    model.compile(loss='categorical_crossentropy',\n","                  optimizer=opt,\n","                  metrics=['accuracy'])\n","    \n","  elif MODEL_NAME == 'LeNet':\n","    model = keras.Sequential(\n","        [\n","          keras.layers.InputLayer(input_shape=INPUT_SHAPE),\n","          keras.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\",name='conv2d'),\n","          keras.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\",name='conv2d_1'),\n","          keras.layers.MaxPooling2D(pool_size=(2, 2), name= 'max_pooling2d_1'),\n","          keras.layers.Dropout(0.25,name='dropout'),\n","          keras.layers.Flatten(name='flatten'),\n","          keras.layers.Dense(128,activation='relu',name='dense'),\n","          keras.layers.Dropout(0.25,name='dropout_1'),\n","          keras.layers.Dense(10, activation=\"softmax\", name='softmax'),\n","\n","        ]\n","    )\n","\n","    # As in the github example\n","    def scheduler(epoch, lr):\n","      if epoch < 10:\n","        return lr\n","      else:\n","        return lr * 0.7\n","\n","    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","\n","\n","  else:\n","    raise NameError('The name of the searched model does not exist')\n","\n","# Save the name of the last convolutional layer\n","for layer in model.layers[::-1]:\n","  if isinstance(layer,(keras.layers.Conv2D,keras.layers.Add)):\n","    LAST_CONV_LAYER = layer.name\n","    break\n","\n","print('-'*65)   \n","print('Dataset loaded successfully!')\n","print('-'*65)\n","print('Model summary:')\n","print('-'*14)\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"SrK95JMYQD8-"}},{"cell_type":"code","metadata":{"id":"5eDLwsKL9rMj","cellView":"form"},"source":["#@title Select if you want to load the pretrained weights used in the paper or to train the networks yourself\n","# Training of the models taking into account what model you have chosen\n","def on_button_clicked_load_or_train(_):\n","  global model\n","  global PRETRAINED_WEIGHTS_PATH\n","  # Change to success type button  \n","  button.button_style = 'success'\n","  button.description = 'Option confirmed!'\n","  # Load\n","  if load_or_train.value == 'Load':\n","    print()\n","    PRETRAINED_WEIGHTS_PATH = os.path.join(PRETRAINED_WEIGHTS_AND_MODEL_FOLDER_PATH, f'{DATASET_NAME}_{MODEL_NAME}.h5')\n","    if MODEL_NAME == 'Simple_ConvNet':\n","      pass \n","    elif MODEL_NAME == 'Resnet34_V2':\n","      pass\n","    elif MODEL_NAME == \"LeNet\": \n","      if DATASET_NAME == 'MNIST':\n","        model.load_weights(PRETRAINED_WEIGHTS_PATH)\n","        print('Weights succesfully loaded! Wait until model.evaluate() is performed')\n","        metrics = model.evaluate(test_images, test_labels)\n","        print('Accuracy obtained is',str(round(metrics[1]*100,2))+'%')\n","      if DATASET_NAME == 'Fashion_MNIST':\n","        model.load_weights(PRETRAINED_WEIGHTS_PATH)\n","        print('Weights succesfully loaded! Wait until model.evaluate() is performed')\n","        metrics = model.evaluate(test_images, test_labels)\n","        print('Accuracy obtained is',str(round(metrics[1]*100,2))+'%')\n","      if DATASET_NAME == 'SVHN_Cropped':\n","        model.load_weights(PRETRAINED_WEIGHTS_PATH)\n","        print('Weights succesfully loaded! Wait until model.evaluate() is performed')\n","        metrics = model.evaluate(test_images, test_labels)\n","        print('Accuracy obtained is',str(round(metrics[1]*100,2))+'%')\n","    elif MODEL_NAME == \"Custom_ConvNet\":\n","      model.load_weights('.h5')\n","      print('Weights succesfully loaded! Wait until model.evaluate() is performed')\n","      metrics = model.evaluate(test_images, test_labels)\n","      print('Accuracy obtained is',str(round(metrics[1]*100,2))+'%')\n","    elif MODEL_NAME == \"ResNet32\": \n","      if DATASET_NAME == 'SVHN_Cropped':\n","        model.load_weights(PRETRAINED_WEIGHTS_PATH)\n","        metrics = model.evaluate(test_images, test_labels)\n","        print('Accuracy obtained is',str(round(metrics[1]*100,2))+'%')\n","      elif DATASET_NAME == 'Cifar10':\n","        # Load the model weights and define the \n","        model.load_weights(PRETRAINED_WEIGHTS_PATH)\n","        optimizer = tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n","        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics = ['accuracy'])\n","        print('Weights succesfully loaded! Wait until model.evaluate() is performed')\n","        metrics = model.evaluate(test_images, test_labels)\n","        print('Accuracy obtained is',str(round(metrics[1]*100,2))+'%')\n","  # Train      \n","  elif load_or_train.value == 'Train':\n","    # Training of the models taking into account what model you have chosen\n","    if MODEL_NAME == 'Simple_ConvNet':\n","      # Hyperparameters\n","      batch_size        = 100\n","      epochs            = 70\n","      data_augmentation = False\n","      # Training\n","      history = None  # For recording the history of trainning process.\n","      if not data_augmentation:\n","          print('Not using data augmentation.')\n","          history = model.fit(train_images, train_labels,\n","                    batch_size=batch_size,\n","                    validation_split = 0.02,\n","                    epochs=epochs,\n","                    shuffle=True)\n","      else:\n","          print('Using real-time data augmentation.')\n","          # This will do preprocessing and realtime data augmentation:\n","          datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n","              featurewise_center=False,  # set input mean to 0 over the dataset\n","              samplewise_center=False,  # set each sample mean to 0\n","              featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","              samplewise_std_normalization=False,  # divide each input by its std\n","              zca_whitening=False,  # apply ZCA whitening\n","              zca_epsilon=1e-06,  # epsilon for ZCA whitening\n","              rotation_range=45,  # randomly rotate images in the range (degrees, 0 to 180)\n","              # randomly shift images horizontally (fraction of total width)\n","              width_shift_range=0.1,\n","              # randomly shift images vertically (fraction of total height)\n","              height_shift_range=0.1,\n","              shear_range=0.,  # set range for random shear\n","              zoom_range=0.,  # set range for random zoom\n","              channel_shift_range=0.,  # set range for random channel shifts\n","              # set mode for filling points outside the input boundaries\n","              fill_mode='nearest',\n","              cval=0.,  # value used for fill_mode = \"constant\"\n","              horizontal_flip=True,  # randomly flip images\n","              vertical_flip=False,  # randomly flip images\n","              # set rescaling factor (applied before any other transformation)\n","              rescale=None,\n","              # set function that will be applied on each input\n","              preprocessing_function=None,\n","              # image data format, either \"channels_first\" or \"channels_last\"\n","              data_format=None,\n","              # fraction of images reserved for validation (strictly between 0 and 1)\n","              validation_split=0.02)\n","          # Compute quantities required for feature-wise normalization\n","          # (std, mean, and principal components if ZCA whitening is applied).\n","          datagen.fit(train_images)\n","          # Fit the model on the batches generated by datagen.flow().\n","          history = model.fit(datagen.flow(train_images,train_labels,batch_size=batch_size,shuffle=True,subset='training'),\n","                                          epochs=epochs,\n","                                          validation_data=datagen.flow(train_images,train_labels,batch_size=10,shuffle=True,subset='validation'),\n","                                          )\n","    elif MODEL_NAME == 'Resnet34_V2':\n","      # Scheduler\n","      def scheduler(epoch, lr):\n","        if epoch < 10:\n","          return lr\n","        else:\n","          return lr * 0.9\n","      batch_size = 64\n","      epochs = 20\n","      callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n","      history = model.fit(train_images, train_labels, batch_size ,epochs ,verbose=1, callbacks=[callback] ,validation_split=0.05)\n","    elif MODEL_NAME == \"LeNet\": \n","      # Train with the lr scheduler and with parameters as in the github FSSD_OoD\n","      batch_size = 64\n","      epochs = 14\n","      callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n","      history=model.fit(train_images, train_labels, batch_size ,epochs ,verbose=1, callbacks=[callback] ,validation_split=0.05)\n","    elif MODEL_NAME == \"Custom_ConvNet\":\n","      # Train\n","      batch_size = 64\n","      epochs     = 8\n","      history=model.fit(train_images, train_labels, batch_size ,epochs ,verbose=1, validation_split=0.1)\n","    elif MODEL_NAME == \"ResNet32\":\n","      # Import the function to create the model and create it\n","      from resnet_32 import create_model\n","      model = create_model((32,32,3),10,'ResNet32')\n","      optimizer = tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n","      model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics = ['accuracy'])\n","      history = model.fit(train_images,train_labels, batch_size=250,epochs = 50, validation_split=0.2)\n","\n","    model.save_weights('{}_{}.h5'.format(dataset,MODEL_NAME))\n","  else:\n","    raise NameError('Selected option not available')\n","\n","load_or_train = widgets.Combobox(placeholder='Choose to load or train',\n","        options=['Load', 'Train'],\n","        description='Options:',\n","        ensure_option=True,\n","        disabled=False,\n","        layout = ipw.Layout(width='325px')\n","        )\n","button = widgets.Button(\n","    description='Push the button to confirm',\n","    disabled=False,\n","    button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n","    tooltip='Click me',\n","    icon='check',\n","    layout = ipw.Layout(width='325px')\n",")\n","button.on_click(on_button_clicked_load_or_train)\n","display(load_or_train)\n","display(button)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ixwDvQ0fZXrO"},"source":["---\n","# ***Training of the OOD detector***\n","---"]},{"cell_type":"code","metadata":{"id":"2iN3AWBRa8cc","cellView":"form"},"source":["#@title Select the value of the seed for shuffling the train array, reponsible of cluster creation. \n","#@markdown In the paper, seed = 8 is used.\n","selected_seed = widgets.IntText(\n","    value='8',\n","    ensure_option=True,\n","    disabled=False,\n","    layout = ipw.Layout(width='150px')\n",")\n","text = 'Enter the value of the seed:'\n","instructions = ipw.widgets.HTML(text)\n","display(instructions)\n","display(selected_seed)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"QEvyCeyxPhxw"}},{"cell_type":"code","metadata":{"id":"kAY0GDucyIWC","cellView":"form"},"source":["#@title Generate the heatmaps for each class to clusterize\n","# Create a shuffled copy to train\n","!mkdir -p objects\n","SEED = selected_seed.value\n","NUMBER_OF_INSTANCES_PER_CLASS = 1000\n","train_images_shuffled, train_labels_shuffled = shuffle(train_images,train_labels,random_state=SEED)\n","# Creation of the arary with N heatmaps per class. This heatmaps are the ones \n","# used for creating the clusters. \n","# Shape = (number_of_classes, number_of_heatmaps, height,width)\n","file_name_heatmaps_train_per_class = f'heatmaps_train_per_class_{DATASET_NAME}_{MODEL_NAME}_{load_or_train.value}_seed{SEED}.npy'\n","path_heatmaps_train_per_class = os.path.join(OBJS_DIR_NAME, file_name_heatmaps_train_per_class)\n","if os.path.isfile(path_heatmaps_train_per_class):\n","  heatmaps_train_per_class = np.load(path_heatmaps_train_per_class)\n","  print('Heatmaps loaded from file')\n","else:\n","  print('Heatmap generation:')\n","  heatmaps_train_per_class = creation_of_heatmaps_per_class(NUMBER_OF_INSTANCES_PER_CLASS,train_images_shuffled,train_labels_shuffled) \n","  np.save(path_heatmaps_train_per_class, heatmaps_train_per_class, allow_pickle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"ODkID3DwPjXu"}},{"cell_type":"code","metadata":{"id":"uPVuCZBJUTVk","cellView":"form"},"source":["#@title Compute the distance matrix with pairwise SSIM distance\n","# Creation of the matrix with the Dssim values in pairs (15 mins approx.)\n","!mkdir -p objects\n","file_name_pairwise_dist_matrix = f'ssim_distance_matrix_per_class_{DATASET_NAME}_{MODEL_NAME}_{load_or_train.value}_seed{SEED}.npy'\n","path_pairwise_dist_matrix = os.path.join(OBJS_DIR_NAME, file_name_pairwise_dist_matrix)\n","if os.path.isfile(path_pairwise_dist_matrix):\n","  ssim_distance_matrix_per_class = np.load(path_pairwise_dist_matrix)\n","  print('Distance matrix loaded from file')\n","else:\n","  print('Pairwise distances matrix computation:')\n","  ssim_distance_matrix_per_class = np.zeros((NUM_CLASSES,heatmaps_train_per_class.shape[1],heatmaps_train_per_class.shape[1])) \n","  for class_index in tqdm(range(NUM_CLASSES)):\n","    ssim_distance_matrix_per_class[class_index] = ssim_distance_matrix_creation(heatmaps_train_per_class[class_index])\n","  np.save(path_pairwise_dist_matrix, ssim_distance_matrix_per_class, allow_pickle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"7y5-QcjtPlU4"}},{"cell_type":"code","metadata":{"id":"Q0lEvbFFl5sJ","cellView":"form"},"source":["#@title Create the clusters for each class\n","# Definition of the distance threshold (parameter for the Agglomerative clustering) for each class\n","# We try different distance thresholds and select the one whose silhouette score is the greatest in the defined range\n","print('Selecting the parameter \"distance_threshold\" of Agglomerative Clustering by optimizing the Silhouette score\\n')\n","distance_threshold = []\n","range_of_dist_thrs = np.linspace(0.52,0.90,39)\n","silhouette_scores_per_class = []\n","clustering_labels_per_class = np.zeros((NUM_CLASSES,ssim_distance_matrix_per_class.shape[1]))\n","for class_index in tqdm(range(NUM_CLASSES)):\n","  silh_scores_one_class = []\n","  for dist in range_of_dist_thrs:\n","    # For each distance threshold, we compute the clustering and the silhouette score\n","    cluster_model = AgglomerativeClustering(n_clusters=None,affinity='precomputed',linkage='complete',distance_threshold=dist)\n","    cluster_model.fit(ssim_distance_matrix_per_class[class_index])\n","    clustering_labels_per_class[class_index] = cluster_model.labels_\n","    try:\n","      silh_scores_one_class.append(silhouette_score(ssim_distance_matrix_per_class[class_index],clustering_labels_per_class[class_index],metric='precomputed'))\n","    except ValueError:\n","      silh_scores_one_class.append(0)    \n","  silhouette_scores_per_class.append(silh_scores_one_class)\n","  '''\n","  for i,score in enumerate(silh_scores[::-1]):\n","    if i != 0:\n","      if score < previous_score:\n","        # We keep the index of the number just before the slope descends (plots below).\n","        distance_threshold.append(range_of_dist_thrs[len(silh_scores)-(i)])\n","        break\n","    previous_score = score\n","  '''\n","  positions = []\n","  max_score = max(silh_scores_one_class)\n","  for index, score in enumerate(silh_scores_one_class[::-1]):\n","    if score == max_score:\n","      positions.append(index)\n","  # We select the max silhouette score closer to distance_threshold = 0  \n","  distance_threshold.append(range_of_dist_thrs[len(range_of_dist_thrs)-positions[-1]-1])\n","\n","print('')\n","# Plot to see the silhouette scores\n","plt.subplots(2,5,figsize=(25,10))\n","for class_index,position in enumerate(range(1,11)):\n","  plt.subplot(2,5,position).plot(range_of_dist_thrs,silhouette_scores_per_class[class_index],color='red')\n","  plt.title(CLASS_NAMES[class_index])\n","plt.savefig('silhouetteScores.pdf')\n","plt.show()\n","\n","\n","# Function that creates de clusters of each class\n","# Initialization of the array containing the labels of the labels for each image in each class\n","clustering_labels_per_class = np.zeros((NUM_CLASSES,ssim_distance_matrix_per_class.shape[1]))\n","# plot the top three levels of the dendrogram\n","w = 40\n","h = 15\n","fig,ax = plt.subplots(2,5,figsize=(w,h))\n","fig.suptitle('Hierarchical Clustering Dendrogram',fontsize = h + w*0.1,y=0.94)\n","for class_index in range(NUM_CLASSES):\n","  if isinstance(distance_threshold,list):\n","    cluster_model = AgglomerativeClustering(n_clusters=None,affinity='precomputed',linkage='complete',distance_threshold=distance_threshold[class_index])\n","  else:\n","    cluster_model = AgglomerativeClustering(n_clusters=None,affinity='precomputed',linkage='complete',distance_threshold=distance_threshold)\n","  cluster_model.fit(ssim_distance_matrix_per_class[class_index])\n","  clustering_labels_per_class[class_index] = cluster_model.labels_\n","  if class_index < 5:\n","    i = 0\n","    j = class_index\n","  else:\n","    i = 1\n","    j = class_index - 5\n","  plot_dendrogram(cluster_model, truncate_mode='level', p=2, ax=ax[i,j])\n","  ax[i,j].set_title('Class {}'.format(CLASS_NAMES[class_index]),fontsize = h)\n","  #ax[i,j].set_xlabel(\"Number of points in node\",fontsize=h)\n","plt.savefig('DendrogramPerClass.pdf')\n","fig.show()\n","print('-'*100,'\\n')\n","for class_index in range(NUM_CLASSES):\n","  a = clustering_labels_per_class[class_index]\n","  unique, counts = np.unique(a, return_counts=True)\n","  print('Class',CLASS_NAMES[class_index].ljust(15),'\\t',dict(zip(unique, counts)))\n","  print('-'*75)\n","print('\\n'+'-'*100)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"vzkMZPTnPp-W"}},{"cell_type":"markdown","metadata":{"id":"Aj0Ua9jAMT9I"},"source":["## Creation of the clusters mean/medians"]},{"cell_type":"code","source":["#@title Select the approach\n","STYLE = {'description_width': 'initial'}\n","WIDTH = '500px'\n","mean_or_median = widgets.Combobox(placeholder='Choose mean or median',\n","        options=['Mean', 'Median'],\n","        description='Average mode:',\n","        ensure_option=True,\n","        disabled=False,\n","        layout = ipw.Layout(width=WIDTH),\n","        style=STYLE\n","        )\n","all_or_percentage = widgets.Combobox(placeholder='Choose all heatmaps or a percentaje of closest ones',\n","        options=['All', 'Percentage'],\n","        description='Average computation:',\n","        ensure_option=True,\n","        disabled=False,\n","        layout = ipw.Layout(width=WIDTH),\n","        style=STYLE\n","        )\n","button_approach = widgets.Button(\n","    description='Push the button to confirm',\n","    disabled=False,\n","    button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n","    tooltip='Click me',\n","    icon='check',\n","    layout = ipw.Layout(width=WIDTH),\n","    style=STYLE\n",")\n","# HTML text\n","text_percentage = 'Select or enter the percentage value (in the paper 10% is used):'\n","instructions_percentage = ipw.widgets.HTML(text_percentage)\n","percentage = widgets.IntSlider(placeholder='Choose the percetage:',\n","        value=10,\n","        min=10,\n","        max=100,\n","        ensure_option=True,\n","        disabled=False,\n","        layout = ipw.Layout(width=WIDTH),\n","        style=STYLE\n","        )\n","button_percentage = widgets.Button(\n","    description='Push the button to confirm',\n","    disabled=False,\n","    button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n","    tooltip='Click me',\n","    icon='check',\n","    layout = ipw.Layout(width=WIDTH),\n","    style=STYLE\n",")\n","def on_button_clicked_approach_definition(_):\n","  global average_heatmaps_per_class_and_cluster\n","  global AGG_FUNCT\n","  AGG_FUNCT = mean_or_median.value\n","  button_approach.button_style = 'success'\n","  if all_or_percentage.value == 'Percentage':\n","    button_approach.description = 'Success!'\n","    instructions_percentage.layout.visibility = 'visible'\n","    button_percentage.layout.visibility = 'visible'\n","    percentage.layout.visibility = 'visible'\n","  else:\n","    global PERCENTAGE_THRESHOLD\n","    button_approach.description = 'Options confirmed!'\n","    instructions_percentage.layout.display = 'none'\n","    button_percentage.layout.display = 'none'\n","    percentage.layout.display = 'none'\n","    PERCENTAGE_THRESHOLD = None\n","    # Create the average heatmaps\n","    file_name_average_heatmaps = f'average_heatmaps_per_class_and_cluster_{DATASET_NAME}_{MODEL_NAME}_{load_or_train.value}_seed{SEED}_{AGG_FUNCT}_{all_or_percentage.value}.pkl'\n","    path_heatmaps_average_heatmaps = os.path.join(OBJS_DIR_NAME, file_name_average_heatmaps)\n","    # Checks if it exists\n","    if os.path.isfile(path_heatmaps_average_heatmaps):\n","      print('File exist, it will be loaded')\n","      with open(path_heatmaps_average_heatmaps, \"rb\") as f:\n","        average_heatmaps_per_class_and_cluster = pickle.load(f)\n","    else:\n","      average_heatmaps_per_class_and_cluster = []\n","      print('Computing the average:')\n","      for class_index in tqdm(range(NUM_CLASSES)):\n","        average_heatmaps_per_class_and_cluster.append(compute_average_heatmaps_per_cluster(clustering_labels_per_class[class_index],heatmaps_train_per_class[class_index], ssim_distance_matrix_per_class[class_index], agg_funct=AGG_FUNCT,thr=PERCENTAGE_THRESHOLD))\n","      with open(path_heatmaps_average_heatmaps, \"wb\") as f:\n","        pickle.dump(average_heatmaps_per_class_and_cluster, f)\n","\n","\n","def on_button_clicked_percentage_definition(_):\n","  global PERCENTAGE_THRESHOLD\n","  global average_heatmaps_per_class_and_cluster\n","  button_percentage.button_style = 'success'\n","  PERCENTAGE_THRESHOLD = percentage.value*0.01\n","  button_percentage.description = 'Percentage confirmed!'\n","  # Create the average heatmaps\n","  file_name_average_heatmaps = f'average_heatmaps_per_class_and_cluster_{DATASET_NAME}_{MODEL_NAME}_{load_or_train.value}_seed{SEED}_{AGG_FUNCT}_{all_or_percentage.value}_{PERCENTAGE_THRESHOLD}.pkl'\n","  path_heatmaps_average_heatmaps = os.path.join(OBJS_DIR_NAME, file_name_average_heatmaps)\n","  # Checks if it exists\n","  if os.path.isfile(path_heatmaps_average_heatmaps):\n","    print('File exist, it will be loaded')\n","    with open(path_heatmaps_average_heatmaps, \"rb\") as f:\n","      average_heatmaps_per_class_and_cluster = pickle.load(f)\n","  else:\n","    average_heatmaps_per_class_and_cluster = []\n","    print('Computing the average:')\n","    all = []\n","    perc = []\n","    for class_index in tqdm(range(NUM_CLASSES)):\n","      average_heatmaps_per_class_and_cluster.append(compute_average_heatmaps_per_cluster(clustering_labels_per_class[class_index],heatmaps_train_per_class[class_index], ssim_distance_matrix_per_class[class_index], agg_funct=AGG_FUNCT,thr=PERCENTAGE_THRESHOLD))\n","    with open(path_heatmaps_average_heatmaps, \"wb\") as f:\n","      pickle.dump(average_heatmaps_per_class_and_cluster, f)\n","\n","\n","# Hide the percentage selection\n","instructions_percentage.layout.visibility = 'hidden'\n","percentage.layout.visibility = 'hidden'\n","button_percentage.layout.visibility = 'hidden'\n","\n","button_approach.on_click(on_button_clicked_approach_definition)\n","button_percentage.on_click(on_button_clicked_percentage_definition)\n","display(mean_or_median)\n","display(all_or_percentage)\n","display(button_approach)\n","print('')\n","display(instructions_percentage)\n","display(percentage)\n","display(button_percentage)\n","print('')"],"metadata":{"id":"QhlD5sYGTexZ","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"8j01Xm0pPn-O"}},{"cell_type":"code","metadata":{"id":"ZFOSxKy4AkIG","cellView":"form"},"source":["#@title Plot the average heatmaps of each cluster of each class\n","# Plot de los heatmaps de cada clase\n","superimposed = False\n","# Calculate the number of total columns\n","max_cols = []\n","for htmap_prom_cluster in average_heatmaps_per_class_and_cluster:\n","  max_cols.append(len(htmap_prom_cluster))\n","max_cols = max(max_cols)\n","FONTSIZE = 10+2*max_cols \n","# Plots\n","fig, ax = plt.subplots(nrows=NUM_CLASSES,ncols=max_cols, figsize = (3*max_cols,3*NUM_CLASSES),sharex=True,sharey=True,constrained_layout=False,tight_layout=False)\n","for class_index in range(NUM_CLASSES):\n","  for cluster in range(len(average_heatmaps_per_class_and_cluster[class_index])):\n","    if superimposed == False:\n","      im = ax[class_index,cluster].imshow(average_heatmaps_per_class_and_cluster[class_index][cluster],cmap='jet',vmin=0,vmax=1)\n","    elif superimposed == True:\n","      one_image_of_class_index = search_index_of_class(class_index,1,train_labels_shuffled)[0]\n","      ax[class_index,cluster].imshow(train_images_shuffled[one_image_of_class_index,:,:,0])\n","       # Save AxesImage for plotting the colorbar\n","      im = ax[class_index,cluster].imshow(resize(average_heatmaps_per_class_and_cluster[class_index][cluster], (train_images_shuffled.shape[1:3])),alpha = 0.6,cmap='jet',vmin=0,vmax=1)\n","\n","    if class_index == 0:\n","      ax[class_index,cluster].set_title('Cluster {}'.format(cluster),fontsize=FONTSIZE)\n","      ax[class_index,cluster].set_xticks([])\n","      ax[class_index,cluster].set_yticks([])\n","    # Comment the line in the if to not plot the class names\n","    if cluster == 0:\n","      ax[class_index,cluster].set_ylabel(CLASS_NAMES[class_index].title(),rotation = 90, fontsize=FONTSIZE)\n","      pass\n","\n","  if len(average_heatmaps_per_class_and_cluster[class_index]) != max_cols:\n","    for empty_ax_index in range(len(average_heatmaps_per_class_and_cluster[class_index]),max_cols):\n","      ax[class_index][empty_ax_index].imshow(np.zeros(np.shape(average_heatmaps_per_class_and_cluster[class_index][cluster])),vmin=0,vmax=1)\n","      ax[class_index,empty_ax_index].plot([0,len(average_heatmaps_per_class_and_cluster[class_index][cluster])-1],[len(average_heatmaps_per_class_and_cluster[class_index][cluster])-1,0],c='w',lw=2)\n","      ax[class_index,empty_ax_index].plot([0,len(average_heatmaps_per_class_and_cluster[class_index][cluster])-1],[0,len(average_heatmaps_per_class_and_cluster[class_index][cluster])-1],c='w',lw=2)\n","      if class_index == 0:\n","        ax[class_index,empty_ax_index].set_title('Cluster {}'.format(empty_ax_index),fontsize=FONTSIZE)\n","        ax[class_index,empty_ax_index].set_xticks([])\n","        ax[class_index,empty_ax_index].set_yticks([])\n","\n","plt.subplots_adjust(wspace=0.1, hspace=0.05)\n","cbar = fig.colorbar(im, ax=ax, shrink=0.6, pad=0.08, aspect=30)\n","cbar.ax.tick_params(labelsize=12+max_cols*4)\n","\n","plt.savefig('./Heatmaps_per_class_and_cluster_{}.pdf'.format(AGG_FUNCT),dpi=40,bbox_inches='tight')\n","plt.savefig('./Heatmaps_per_class_and_cluster_{}.png'.format(AGG_FUNCT),dpi=250,bbox_inches='tight')\n","#plt.savefig('./Crop.pdf'.format(modo_heatmaps),dpi=40,bbox_inches=Bbox([[0, 3], [9, 27]]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gUGxMTHkRDug"},"source":["---\n","# ***Test the detector***\n","---"]},{"cell_type":"markdown","metadata":{"id":"PB3iRHA0Rip2"},"source":["## Train, Test and OD dataset heatmap creation"]},{"cell_type":"markdown","source":["Now we have to generate the heatmaps for:\n","1. **Train**: random subset of the train instances to define the threshold values that doesn't intesect with the one used for the training phase.\n","1. **Test**: test set of the data (10.000 samples) used to compute the metrics\n","1. **OoD**: OoD test set of the OoD data used to compute the metrics"],"metadata":{"id":"wLcoqVKpXQ14"}},{"cell_type":"code","metadata":{"cellView":"form","id":"lkS5NKgh8nFX"},"source":["#@title Generate the heatmaps of test and OD datasets\n","\n","'''\n","if len(train_images_shuffled) > 60000:\n","  train_images_shuffled = train_images_shuffled[:60000]\n","train_predictions = np.argmax(model.predict(train_images_shuffled[-10000:]),axis=1)\n","train_heatmaps = generate_heatmaps(train_images_shuffled[-10000:],train_predictions)\n","'''\n","# Test heatmaps and predictions\n","test_predictions = np.argmax(model.predict(test_images),axis=1)\n","file_name_test_heatmaps = f'test_heatmaps_{DATASET_NAME}_{MODEL_NAME}_trainedOn{DATASET_NAME}.npy'\n","path_test_heatmaps = os.path.join(OBJS_DIR_NAME, file_name_test_heatmaps)\n","if os.path.isfile(path_test_heatmaps):\n","  print(f'Test heatmaps for {selectedDataset.value} exist, they will be loaded')\n","  test_heatmaps = np.load(path_test_heatmaps)\n","else:\n","  print('Generating the test heatmaps:')\n","  if len(test_images) > 10000:\n","    test_images = test_images[:10000]\n","  test_heatmaps = generate_heatmaps(test_images,test_predictions)\n","  np.save(path_test_heatmaps, test_heatmaps, allow_pickle=False)\n","\n","# Load the selected OD dataset\n","NUM_CLASSES_OD = 10\n","OD_DATASET_NAME = OD_dataset.value\n","od_test_images, _ = load_test_sample_of_dataset(OD_DATASET_NAME) \n","# OoD heatmaps and predictions\n","od_predictions = np.argmax(model.predict(od_test_images),axis=1)\n","file_name_od_test_heatmaps = f'od_test_heatmaps_{OD_DATASET_NAME}_{MODEL_NAME}_trainedOn{DATASET_NAME}.npy'\n","path_od_test_heatmaps = os.path.join(OBJS_DIR_NAME, file_name_od_test_heatmaps)\n","if os.path.isfile(path_od_test_heatmaps):\n","  print(f'OoD heatmaps for {OD_DATASET_NAME} exist, they will be loaded')\n","  od_heatmaps = np.load(path_od_test_heatmaps)\n","else:\n","  print(f'Generating the Out-of-Distribution heatmaps of {OD_DATASET_NAME} dataset:')\n","  if len(od_test_images) > 10000:\n","    od_test_images = od_test_images[:10000]\n","  od_heatmaps = generate_heatmaps(od_test_images,od_predictions)\n","  np.save(path_od_test_heatmaps, od_heatmaps, allow_pickle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"itd_fFZ9P-6i"}},{"cell_type":"markdown","source":["## Compute SSIM of test and OoD"],"metadata":{"id":"kMAmFgewDls8"}},{"cell_type":"code","source":["#@title Select the ood function\n","STYLE = {'description_width': 'initial'}\n","WIDTH = '500px'\n","ood_funct_options = ['Compare to centroids', 'Compare to each heatmaps of the closest cluster']\n","widget_ood_function = widgets.Combobox(placeholder='Choose one',\n","        options=ood_funct_options,\n","        description='Comparison against:',\n","        ensure_option=True,\n","        disabled=False,\n","        layout = ipw.Layout(width=WIDTH),\n","        style=STYLE\n","        )\n","button_ood_function = widgets.Button(\n","    description='Push the button to run the ood function',\n","    disabled=False,\n","    button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n","    tooltip='Click me',\n","    icon='check',\n","    layout = ipw.Layout(width=WIDTH),\n","    style=STYLE\n",")\n","# HTML text\n","text_ood_function = 'Select the ood function:'\n","instructions_ood_function = ipw.widgets.HTML(text_ood_function)\n","def on_button_clicked_ood_function(_):\n","  global ssim_per_image_test\n","  global ssim_per_image_od\n","  global ood_function\n","  button_ood_function.button_style = 'success'\n","  button_ood_function.description = 'Success!'\n","  if widget_ood_function.value == ood_funct_options[0]:\n","    print('Comparison against centroids is being performed:')\n","    ood_function = 'Centroids'\n","    # Test\n","    ssim_per_image_test = compute_ssim_against_cluster_averages(test_heatmaps,test_predictions,average_heatmaps_per_class_and_cluster)\n","    # OD\n","    ssim_per_image_od = compute_ssim_against_cluster_averages(od_heatmaps,od_predictions,average_heatmaps_per_class_and_cluster)\n","  else:\n","    # Test\n","    ood_function = 'ClosestClusterAll'\n","    file_name_ood_function_test = f'ssim_all_heatmaps_of_closest_cluster_{DATASET_NAME}_vs_{DATASET_NAME}_{MODEL_NAME}_{AGG_FUNCT}.npy'\n","    path_ood_function_test = os.path.join(OBJS_DIR_NAME, file_name_ood_function_test)\n","    if os.path.isfile(path_ood_function_test):\n","      print(f'SSIM values of {DATASET_NAME}_vs_{DATASET_NAME}_{MODEL_NAME} exist, they will be loaded')\n","      ssim_per_image_test = np.load(path_ood_function_test)\n","    else:\n","      print(f'Comparison of {DATASET_NAME} against all heatmaps of the closest cluster of {DATASET_NAME} is being performed:')\n","      ssim_per_image_test = compute_ssim_against_all_heatmps_of_closest_cluster(test_heatmaps,test_predictions,average_heatmaps_per_class_and_cluster,heatmaps_train_per_class,clustering_labels_per_class)\n","      np.save(path_ood_function_test, ssim_per_image_test, allow_pickle=False)\n","    # OD\n","    print('')\n","    file_name_ood_function_od = f'ssim_all_heatmaps_of_closest_cluster {DATASET_NAME} vs {OD_DATASET_NAME}_{MODEL_NAME}_{AGG_FUNCT}.npy'\n","    path_ood_function_od = os.path.join(OBJS_DIR_NAME, file_name_ood_function_od)\n","    if os.path.isfile(path_ood_function_od):\n","      print(f'SSIM values of {OD_DATASET_NAME}_{MODEL_NAME} exist, they will be loaded')\n","      ssim_per_image_od = np.load(path_ood_function_od)\n","    else:\n","      print(f'Comparison of {OD_DATASET_NAME} against all heatmaps of the closest cluster of {DATASET_NAME} is being performed:')\n","      ssim_per_image_od = compute_ssim_against_all_heatmps_of_closest_cluster(od_heatmaps,od_predictions,average_heatmaps_per_class_and_cluster,heatmaps_train_per_class,clustering_labels_per_class)\n","      np.save(path_ood_function_od, ssim_per_image_od, allow_pickle=False)\n","\n","button_ood_function.on_click(on_button_clicked_ood_function)\n","display(instructions_ood_function)\n","display(widget_ood_function)\n","display(button_ood_function)"],"metadata":{"cellView":"form","id":"jwHwmWBVs8Xl"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kALZGyI4nIEh","cellView":"form"},"source":["#@title Histogram of SSIM values per class\n","# Funcion que representa el % de instancias que SI activan el threshold tanto CON como SIN deriva \n","# Inicializar los rangos para los que se calcula la CDF\n","x = np.linspace(-1,1,100)\n","y = np.linspace(1,-1,100)\n","\n","# Propiedades de la caja donde va el texto\n","props               = dict(boxstyle='round', facecolor='azure', alpha=0.8)\n","meanBoxProps        = dict(boxstyle='round', facecolor='springgreen', alpha=0.7)\n","meanOutDistBoxProps = dict(boxstyle='round', facecolor='lightcoral', alpha=0.7)\n","# Creacion de figura\n","fig, ax = plt.subplots(2,5,sharey=True,figsize=(40,14))\n","plot_verde  = 'In-Distribution'   \n","plot_rojo   = 'Out-Distribution'\n","fig.suptitle('Histogram In-Distribution VS {}'.format(plot_rojo), fontsize=25,y=0.96)\n","\n","for class_index in range(10):\n","  # The count of how many od images are classified as each class\n","  unique, od_counts = np.unique(od_predictions, return_counts=True)\n","  # KDE fitting\n","  kde_sci = stats.gaussian_kde(ssim_per_image_test[np.where(test_predictions==class_index)])\n","  cdf = []\n","  for i in x:\n","    cdf.append(kde_sci.integrate_box_1d(-1,i))\n","  # KDE fitting\n","  try:\n","    if od_counts[class_index] > 50:\n","      kde_sci_OOD = stats.gaussian_kde(ssim_per_image_od[np.where(od_predictions==class_index)])\n","      cdf_OOD = []\n","      for i in y:\n","        cdf_OOD.append(kde_sci_OOD.integrate_box_1d(i,1))\n","  except KeyError:\n","    raise NameError('Error')\n","    pass\n","  # Calculo del punto de cruce minimizando diferencia entre CDFs. La solucion nos da la posicion del punto de minima \n","  # diferencia dentro del array, no el valor en si\n","  sol = minimize_scalar(cdf_difference,args=(kde_sci,kde_sci_OOD),method='bounded',bounds=(1,99),options={'xatol': 0.001,'maxiter': 100, 'disp': 0})\n","  # Punto de cruce es el valor del eje X en la posicion de la solucion \n","  p_cruce = x[int(sol.x)]\n","  tpr_cruce = round(kde_sci.integrate_box_1d(p_cruce,1),3)\n","  fpr_cruce = round(1-kde_sci_OOD.integrate_box_1d(-1,p_cruce),3)\n","  \n","  # Definicion de i y j para plotear bien\n","  i=0\n","  j=class_index\n","  if class_index >= 5:\n","    i = 1\n","    j = class_index-5\n","\n","  # Plots de KDE\n","  ax[i,j].set_xlim((-0.1,1))\n","  ax[i,j].set_ylim((0,4))\n","  ax[i,j].set_yticks([])\n","  ax[i,j].hist(ssim_per_image_test[np.where(test_predictions==class_index)], density=True,bins=25,color='green',label=plot_verde)\n","  ax[i,j].hist(ssim_per_image_od[np.where(od_predictions==class_index)], density=True,bins=25,color='red',alpha=0.6,label=plot_rojo)\n","  ax[i,j].plot(x, kde_sci.pdf(x), lw=3, label='PDF {}'.format(plot_verde), color='limegreen',zorder=1)\n","  #ax[i,j].plot(x, cdf, lw=3, label='CDF {}'.format(plot_verde), color='chartreuse',zorder=2)\n","  ax[i,j].set_title('Represented class: {}'.format(CLASS_NAMES[class_index]),fontsize=16)\n","\n","  meanInDistPerClass = round(ssim_per_image_test[np.where(test_predictions==class_index)].mean(),2)\n","  ax[i,j].text(x=meanInDistPerClass,y=0.35,s='Mean\\n'+str(meanInDistPerClass),fontsize=16,fontweight='medium',bbox=meanBoxProps,horizontalalignment='center',zorder=4)\n","\n","  # Texto a representar\n","  altura_texto = 0.71\n","  textstr = 'Nº of OD heatmaps: {}'.format(od_counts[class_index])\n","  try:\n","    if od_counts[class_index] > 50:\n","      #ax[i,j].plot(y, cdf_OOD, lw=3, label='CDF {}'.format(plot_rojo), color='orangered',zorder=3)\n","      # Texto\n","      meandOutDistPerClass = round(ssim_per_image_od[np.where(od_predictions==class_index)].mean(),2)\n","      ax[i,j].text(x=meandOutDistPerClass,y=0.35,s='Mean\\n'+str(meandOutDistPerClass),fontsize=16,fontweight='medium',bbox=meanOutDistBoxProps,horizontalalignment='center',zorder=4)\n","      ax[i,j].text(0.98, altura_texto, textstr, transform=ax[i,j].transAxes, fontsize=12,horizontalalignment='right',verticalalignment='center', multialignment='left',bbox=props,zorder=4)\n","    else:\n","      try:\n","        meandOutDistPerClass = round(ssim_per_image_od[np.where(od_predictions==class_index)].mean(),2)\n","        ax[i,j].text(x=meandOutDistPerClass,y=0.35,s='Mean\\n'+str(meandOutDistPerClass),fontsize=16,fontweight='medium',bbox=meanOutDistBoxProps,horizontalalignment='center',zorder=4)\n","\n","        ax[i,j].text(0.98, altura_texto, textstr, transform=ax[i,j].transAxes, fontsize=12,horizontalalignment='right',verticalalignment='center', multialignment='left',bbox=props,zorder=4)\n","      except:\n","        textstr = 'Nº inputs: 0'\n","      ax[i,j].text(0.98, altura_texto, textstr, transform=ax[i,j].transAxes, fontsize=12,horizontalalignment='right',verticalalignment='center', multialignment='left',bbox=props,zorder=4)\n","\n","  except KeyError:\n","    textstr = 'Nº inputs: 0'\n","    ax[i,j].text(0.98, altura_texto, textstr, transform=ax[i,j].transAxes, fontsize=12,horizontalalignment='right',verticalalignment='center', multialignment='left',bbox=props,zorder=4)\n","\n","  #ax[i,j].axvline(x=p_cruce, ymin=0, ymax=1,color='fuchsia',label='Threshold',linewidth=3,linestyle='--',zorder=5)\n","  ax[i,j].legend(fontsize=14, loc='upper right')\n","\n","#fig.savefig('./Hist_{}_vs_{}'.format(plot_verde,plot_rojo),dpi=200)\n","fig.savefig('./Hist_{}_vs_{}.pdf'.format(plot_verde,plot_rojo))"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title AUROC and AUPR\n","''' Using the Similarity (SSIM) '''\n","# Creation of the array with the thresholds for each TPR (class, dist_per_TPR)\n","#ssim_per_class_per_image_train = [ssim_per_image_train[np.where(train_predictions == class_index)] for class_index in range(NUM_CLASSES)]\n","ssim_per_class_per_image_test = [ssim_per_image_test[np.where(test_predictions == class_index)] for class_index in range(NUM_CLASSES)]\n","ssim_per_class_per_image_od = [ssim_per_image_od[np.where(od_predictions == class_index)] for class_index in range(NUM_CLASSES)]\n","similarity_thresholds_test = similarity_thresholds_for_each_TPR(ssim_per_class_per_image_test)\n","# Conmputing precision, tpr and fpr\n","precision, tpr_values, fpr_values = compute_precision_tpr_fpr_for_test_and_OoD_similarity(ssim_per_class_per_image_test, ssim_per_class_per_image_od, similarity_thresholds_test)\n","# Appending that when FPR = 1 the TPR is also 1:\n","tpr_values_auroc = np.append(tpr_values,1)\n","fpr_values_auroc = np.append(fpr_values,1)\n","\n","# Plots and results\n","!mkdir -p results\n","# ROC Curve\n","# AUC\n","auroc = round(np.trapz(tpr_values_auroc, fpr_values_auroc),4)\n","# Plot\n","plt.figure(figsize=(15,12))\n","roc = plt.plot(fpr_values_auroc,tpr_values_auroc,label='ROC curve',lw=3)\n","rnd_roc = plt.plot(np.linspace(0,1,100),np.linspace(0,1,100),'k--',label='Random ROC curve')\n","plt.xticks(fontsize=15)\n","plt.yticks(fontsize=15)\n","plt.xlabel('FPR',fontsize=20)\n","plt.ylabel('TPR',fontsize=20)\n","plt.title('ROC curve, AUC = %.4f'%auroc,fontsize=25,pad=10)\n","plt.fill_between(fpr_values_auroc,tpr_values_auroc,alpha=0.3)\n","# Create empty plot with blank marker containing the extra label\n","fpr_95 = round(fpr_values_auroc[int(len(fpr_values_auroc)*0.95)],4)\n","fpr_80 = round(fpr_values_auroc[int(len(fpr_values_auroc)*0.80)],4)\n","plt.plot([], [], ' ', label=f'FPR at 95% TPR = {fpr_95*100:.2f}%')\n","plt.plot([], [], ' ', label=f'FPR at 80% TPR = {fpr_80*100:.2f}%')\n","#plt.text(0.60,0.975,'FPR at 95% TPR = {}%'.format(round(array_TPR_FPR_x_threshold[95,1]*100,2)),fontsize=20,bbox=dict(boxstyle=\"round\",facecolor='white', alpha=0.5))\n","plt.legend(fontsize=20,loc='upper left')\n","plt.savefig(f'/content/AUROC_{DATASET_NAME}_vs_{OD_DATASET_NAME}.pdf')\n","plt.show()\n","\n","# PR Curve\n","# AUC\n","aupr = round(np.trapz(precision, tpr_values),4)\n","# Plot\n","plt.figure(figsize=(15,12))\n","roc = plt.plot(tpr_values,precision,label='PR curve',lw=3)\n","plt.xticks(fontsize=15)\n","plt.yticks(fontsize=15)\n","plt.xlabel('FPR',fontsize=20)\n","plt.ylabel('Precision',fontsize=20)\n","plt.title('PR curve, AUC = %.4f'%aupr,fontsize=25,pad=10)\n","plt.fill_between(tpr_values,precision,alpha=0.3)\n","plt.legend(fontsize=20,loc='upper left')\n","plt.savefig(f'/content/AUPR_{DATASET_NAME}_vs_{OD_DATASET_NAME}.pdf')\n","plt.show()\n","df = pd.DataFrame(data=[[auroc,aupr,fpr_95,fpr_80]], columns=['AUROC','AUPR','FPR95','FPR80'])\n","if PERCENTAGE_THRESHOLD is not None:\n","  df.to_csv(f'results/Results_{DATASET_NAME}_vs_{OD_DATASET_NAME}_{ood_function}_{AGG_FUNCT}_percentage{PERCENTAGE_THRESHOLD}.csv',index=False, columns=['AUROC','AUPR','FPR95','FPR80'],sep=';',decimal=',')\n","else:\n","  df.to_csv(f'results/Results_{DATASET_NAME}_vs_{OD_DATASET_NAME}_{ood_function}_{AGG_FUNCT}_all.csv',index=False, columns=['AUROC','AUPR','FPR95','FPR80'],sep=';',decimal=',')\n","# Print info\n","print('  ----------------------------------')\n","print('| Results saved in results directory |')\n","print('  ----------------------------------')"],"metadata":{"id":"TqTUKrf9XvSh","cellView":"form"},"execution_count":null,"outputs":[]}]}